---
title: "Taller KS"
author: "Leonardo Enciso"
date: "6/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
pesos<-c(9.9,
11.2,
13.6,
13.4,
7.8,
7.8,
8.8,
15.2,
13.4,
11.2,
9.3,
13.9,
14.3,
14.3,
11.4,
15.5,
11.2,
15.7,
11.8,
13.7,
13.6,
14.2,
10.7,
16.3,
7.8,
12.6,
13.0,
12.1,
10.7,
15.5,
13.2,
15.1,
9.5,
10.6,
14.0,
15.8,
12.6,
6.8,
13.5,
12.9,
12.2,
17.1,
9.9,
19.7,
12.6,
11.2,
12.6,
14.0,
14.0,
7.3,
7.7,
10.9,
10.4,
9.2,
14.1,
14.7,
11.3,
9.2,
10.0,
9.2,
10.7,
13.8,
8.8,
12.4,
9.6,
9.3,
8.2,
9.2,
15.0,
12.2,
9.4,
11.7,
17.3,
12.8,
8.9,
14.9,
8.8,
17.0,
7.3,
14.6,
12.2,
14.9,
6.9,
9.0,
13.6,
8.3,
14.1,
18.0,
12.1,
10.6,
14.7,
13.0,
10.2,
7.7,
11.3,
13.8,
15.4,
13.0,
11.4,
10.6,
10.2,
12.3,
12.1,
14.3,
7.6,
14.6,
12.7,
13.1,
13.8,
15.0,
9.7,
11.1,
10.5,
12.6,
11.4,
10.9,
12.8,
26.4,
15.3,
13.8,
16.4,
11.0,
15.8,
12.7,
8.6,
13.3,
12.5,
14.9,
15.0,
14.2,
13.0,
7.1,
21.0,
13.9,
15.4,
9.8,
13.8,
9.8,
10.9,
15.9,
14.2,
9.3,
14.5,
13.5,
12.3,
8.7,
9.3,
14.2,
12.1,
8.6,
14.9,
7.5,
11.5,
8.3,
18.9,
13.3,
14.6,
9.7,
15.2,
8.0,
11.4,
7.2,
12.5,
7.0,
13.4,
8.3,
12.9,
8.0,
10.1,
7.0,
10.3,
13.8,
14.2,
10.0,
14.2,
16.0,
17.5,
11.3,
16.8,
16.4,
14.5,
12.6,
10.0,
10.9,
6.7,
10.0,
12.3,
14.3,
8.1,
9.0,
14.0,
18.3,
14.5,
12.7,
15.0,
13.8,
11.2,
7.1,
5.5,
10.8,
14.0,
19.5,
7.8,
12.5,
10.0,
8.8
)
```


# Aplicación de pruebas de normalidad y pruebas de bondad y ajuste 

Se realizó la medicion del peso de 206 personas. Se tiene el interés de saber si esta variable proviene de una población con distribución normal con media 10 y desviación estandar igual a 3. Realizar la evaluación utilizando distintas pruebas de bondad y ajuste y la evaluación a través de gráficos.

## Validación de supuestos 
La prueba de bondad de ajuste requiere dos supuestos. El primero es que la variable sea continua, lo cual en este caso se cumple y segundo que la distribución de los datos sea normal. \\

Se realizan los siguientes pasos: 

+ Realizar pruebas para definir si la variable tiene distribución normal 
+ Realizar la estandarización de la variable y dibujar la ecdf 
+ Dibujar la cdf de la distribución teórica 
+ Realizar la prueba de bondad y ajuste de KS para definir si la variable procede de una distribución normal con los parámetros definidos

## Pruebas y gráficos de normalidad 

## Utilizando las herramientas del paquete Graphics 
```{r}
# Histograma
hist(pesos, main="Distribución de los pesos")
# Gráfico de caja 
boxplot(pesos, main="Distribución de los pesos")
# Estandarización del peso 
z.pesos<-(pesos-mean(pesos))/sd(pesos)
# Gráfico QQ
qqnorm(z.pesos)
abline(0,1, col="Red")
# Gráfica de la ecdf 
plot(ecdf(pesos), col ="#db6a28",main="Distribución empírica")
grid(col="Darkgray")
# Gráfica de la normal con parámetros n(10,3)
curve(pnorm(x,10,3),0,20, col = "Blue", main="Distribución teórica")
# Ahora las dos curvas en una gráfica, valores sin estandarizar 
plot(ecdf(pesos), col ="#db6a28",main="Distribuciones")
curve(pnorm(x,10,3),0,20, col = "Blue", add=T)
grid(col="Darkgray")
text(20,0.4,"Empírica", col="#db6a28", cex=0.8)
text(20,0.2,"Teórica", col="Blue", cex=0.8)
```

## Ahora usando ggplot 

```{r}
## Estandarización de la variable peso 
library(tidyverse)
media_peso<-mean(pesos)
sd_peso<-sd(pesos)
peso_y<-(pesos-media_peso)/sd_peso
peso_x<-as.data.frame(pesos)

## Datos sin estandarizar
ggplot(peso_x,aes(x=pesos))+
stat_ecdf(geom="step")+
stat_function(fun=pnorm,color="blue",args = list(10,3))+
labs(title="Empírica_normal vs teórica", y="densidad",x="x")

## Datos estandarizados
peso_estan<-(pesos-media_peso)/sd_peso
peso_estan<-as.data.frame(peso_estan)

ggplot(peso_estan,aes(x=pesos))+
stat_ecdf(geom="step")+
stat_function(fun=pnorm,color="blue",args = list(10,3))+
labs(title="Empírica_normal vs teórica", y="densidad",x="x")

```
Ahora se realizan las pruebas de normalidad. Se aplican varias pruebas de dos librerías diferentes. Primero usando la libreria nortest

```{r}
library(nortest)
## Usando la libreria nortest 
usa_nortest<-function(x){
  anderson<-ad.test(x)
  cramer<-cvm.test(x)
  lillies<-lillie.test(x)
  shapiro.francia<-sf.test(x)
  ## Salida a pantalla 
 print(anderson)
 print(cramer)
 print(lillies)
 print(shapiro.francia)
}
usa_nortest(pesos)

```

Ahora usando el paquete normtest 
```{r}
library(normtest)
usa_normtest<-function(x){
  jarque_a<-ajb.norm.test(x)
  frosini<-frosini.norm.test(x)
  geary<-geary.norm.test(x)
  heg_1<-hegazy1.norm.test(x)
  heg_2<-hegazy2.norm.test(x)
  jarque_b<-jb.norm.test(x)
  kurt<-kurtosis.norm.test(x)
  skek<-skewness.norm.test(x)
  spieg<-spiegelhalter.norm.test(x)
  wb<-wb.norm.test(x)
  ## Salida de datos 
  print(jarque_a)
  print(jarque_b)
  print(frosini)
  print(geary)
  print(heg_1)
  print(heg_2)
  print(kurt)
  print(skek)
  print(wb)
}
usa_normtest(pesos)

```

## Prueba de bondad de ajuste 

El estadístico D de KS es el valor de la distancia máxima vertical entre la función empírica y teórica. La expresión que representa este valor es:

+ $D = max(|S_n(x)-F_n(x)|)$

Gráficamente es dificil definir cual es el punto porque puede que además no este representado en los datos muestrales. 

```{r}
## Aproximación exacta 
ks.test(pesos, "pnorm", 10,3, alternative="two.sided", exact = T)
## Aproximación asintótica 
ks.test(pesos, "pnorm", 10,3, alternative="two.sided", exact = F)
```

Se rechaza la hipótesis nula de que los datos provienen de la distribución normal N(10,3). 
